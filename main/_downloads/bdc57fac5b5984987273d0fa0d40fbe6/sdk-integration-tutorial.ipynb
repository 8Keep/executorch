{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# SDK Integration Tutorial\n\n**Author:** [Jack Khuu](https://github.com/Jack-Khuu)_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The [ExecuTorch SDK](../sdk-overview.html)_ is a set of tools designed to\nprovide users with the ability to profile, debug, and visualize ExecuTorch\nmodels.\n\nThis tutorial will show a full end-to-end flow of how to utilize the SDK.\nSpecifically, it will:\n\n1. Generate the artifacts consumed by the SDK ([ETRecord](../sdk-etrecord)_, [ETDump](../sdk-etdump.html)_).\n2. Create an Inspector class consuming these artifacts.\n3. Utilize the Inspector class to analyze the model.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n\nTo run this tutorial, you\u2019ll need to install ExecuTorch.\n\nSet up a conda environment. To set up a conda environment in Google Colab::\n\n  !pip install -q condacolab\n  import condacolab\n  condacolab.install()\n\n  !conda create --name executorch python=3.10\n  !conda install -c conda-forge flatbuffers\n\nInstall ExecuTorch from source. If cloning is failing on Google Colab, make\nsure Colab -> Setting -> Github -> Access Private Repo is checked::\n\n  !git clone https://{github_username}:{token}@github.com/pytorch/executorch.git\n  !cd executorch && bash ./install_requirements.sh\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate ETRecord (Optional)\n\nThe first step is to generate an ``ETRecord``. ``ETRecord`` contains model\ngraphs and metadata for linking runtime results (such as profiling) to\nthe eager model. This is generated via ``executorch.sdk.generate_etrecord``.\n\n``executorch.sdk.generate_etrecord`` takes in an output file path (str), the\nedge dialect model (``EdgeProgramManager``), the ExecuTorch dialect model\n(``ExecutorchProgramManager``), and an optional dictionary of additional models\n\nIn this tutorial, the mobilenet v2 example model is used to demonstrate::\n\n  # Imports\n  import copy\n  import torch\n\n  from executorch.examples.models.mobilenet_v2 import MV2Model\n  from executorch.exir import (\n      EdgeCompileConfig,\n      EdgeProgramManager,\n      ExecutorchProgramManager,\n      to_edge,\n  )\n  from executorch.sdk import generate_etrecord\n  from torch.export import export, ExportedProgram\n\n  # Generate MV2 Model\n  model: torch.nn.Module = MV2Model()\n\n  aten_model: ExportedProgram = export(\n      model.get_eager_model().eval(),\n      model.get_example_inputs(),\n  )\n\n  edge_program_manager: EdgeProgramManager = to_edge(aten_model, compile_config=EdgeCompileConfig(_check_ir_validity=True))\n  # Note: A copy is needed because the underlying graph_module is modified\n  edge_program_manager_copy = copy.deepcopy(edge_program_manager)\n  et_program_manager: ExecutorchProgramManager = edge_program_manager_copy.to_executorch()\n\n\n  # Generate ETRecord\n  etrecord_path = \"etrecord.bin\"\n  generate_etrecord(etrecord_path, edge_program_manager, et_program_manager)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate ETDump\n\nNext step is to generate an ``ETDump``. ``ETDump`` contains runtime results\nfrom executing the model. To generate, simply pass the ExecuTorch model\nto the ``executor_runner``::\n\n  buck2 run executorch/examples/portable/scripts:export -- -m mv2\n  buck2 run @mode/opt -c executorch.event_tracer_enabled=true executorch/sdk/runners:executor_runner -- --model_path mv2.pte\n\nTODO: Add Instructions for CMake, when landed\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating an Inspector\n\nFinal step is to create the ``Inspector`` by passing in the artifact paths.\nInspector takes the runtime results from ``ETDump`` and correlates them to\nthe operators of the Edge Dialect Graph.\n\nNote: An ``ETRecord`` is not required. If an ``ETRecord`` is not provided,\nthe Inspector will show runtime results without operator correlation.\n\nTo visualize all runtime events, call ``print_data_tabular``::\n\n  from executorch.sdk import Inspector\n\n  etdump_path = \"etdump.etdp\"\n  inspector = Inspector(etdump_path=etdump_path, etrecord_path=etrecord_path)\n  inspector.print_data_tabular()\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyzing with an Inspector\n\n``Inspector`` provides 2 ways of accessing ingested information: [EventBlocks](../sdk-inspector.rst)_\nand ``DataFrames``. These mediums give users the ability to perform custom\nanalysis about their model performance.\n\nBelow are examples usages, with both ``EventBlock`` and ``DataFrame`` approaches::\n\n  # Set Up\n\n  import pprint as pp\n  import pandas as pd\n\n  pd.set_option('display.max_colwidth', None)\n  pd.set_option('display.max_columns', None)\n\nIf a user wants the raw profiling results, they would do something similar to\nfinding the raw runtime data of an ``addmm.out`` event::\n\n  for event_block in inspector.event_blocks:\n      # Via EventBlocks\n      for event in event_block.events:\n          if event.name == 'native_call_addmm.out':\n              print(event.name, event.perf_data.raw)\n\n      # Via Dataframe\n      df = event_block.to_dataframe()\n      df = df[df.event_name == 'native_call_addmm.out']\n      print(df[['event_name', 'raw']])\n      print()\n\nIf a user wants to trace an operator back to their model code, they would do\nsomething similar to finding the module hierarchy and stack trace of the\nslowest ``convolution.out`` call::\n\n  for event_block in inspector.event_blocks:\n      # Via EventBlocks\n      slowest = None\n      for event in event_block.events:\n          if event.name == 'native_call_convolution.out':\n              if slowest is None or event.perf_data.p50 > slowest.perf_data.p50:\n                  slowest = event\n      if slowest is not None:\n          print(slowest.name)\n          print()\n          pp.pprint(slowest.stack_traces)\n          print()\n          pp.pprint(slowest.module_hierarchy\n\n      # Via Dataframe\n      df = event_block.to_dataframe()\n      df = df[df.event_name == 'native_call_convolution.out']\n      if len(df) > 0:\n          slowest = df.loc[df['p50'].idxmax()]\n          print(slowest.event_name)\n          print()\n          pp.pprint(slowest.stack_traces)\n          print()\n          pp.pprint(slowest.module_hierarchy)\n\nIf a user wants the total runtime of a module::\n\n  print(inspector.find_total_for_module(\"L__self___features\"))\n  print(inspector.find_total_for_module(\"L__self___features_14\"))\n\nNote: ``find_total_for_module`` is a special first class method of\n[Inspector](../sdk-inspector.html)_\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nIn this tutorial, we learned about the steps required to consume an ExecuTorch\nmodel with the ExecuTorch SDK. It also showed how to use the Inspector APIs\nto analyze the model run results.\n\n### Links Mentioned\n\n- [ExecuTorch SDK](../sdk-overview.html)_\n- [ETRecord](../sdk-etrecord)_\n- [ETDump](../sdk-etdump.html)_\n- [Inspector](../sdk-inspector.html)_\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}